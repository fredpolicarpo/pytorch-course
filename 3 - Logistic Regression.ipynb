{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Course\n",
    "## Logistic Regression in the PyTorch way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\") \n",
    "\n",
    "x_data = torch.Tensor([[1.], [2.], [3.], [4.]], device=device)\n",
    "y_data = torch.Tensor([[0.], [0.], [1.], [1.]], device=device)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.BCELoss(reduction='elementwise_mean') # Loss Function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Reduction Loss Function\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7016899585723877\n",
      "5 0.7001137733459473\n",
      "10 0.6985501646995544\n",
      "15 0.696997880935669\n",
      "20 0.6954558491706848\n",
      "25 0.6939231157302856\n",
      "30 0.6923990845680237\n",
      "35 0.6908830404281616\n",
      "40 0.689374566078186\n",
      "45 0.687873125076294\n",
      "50 0.6863783597946167\n",
      "55 0.6848902702331543\n",
      "60 0.683408260345459\n",
      "65 0.6819321513175964\n",
      "70 0.6804620027542114\n",
      "75 0.6789974570274353\n",
      "80 0.6775385141372681\n",
      "85 0.6760850548744202\n",
      "90 0.6746368408203125\n",
      "95 0.6731940507888794\n",
      "100 0.671756386756897\n",
      "105 0.6703238487243652\n",
      "110 0.668896496295929\n",
      "115 0.6674741506576538\n",
      "120 0.6660568714141846\n",
      "125 0.6646444797515869\n",
      "130 0.6632371544837952\n",
      "135 0.661834716796875\n",
      "140 0.6604371070861816\n",
      "145 0.6590445637702942\n",
      "150 0.657656729221344\n",
      "155 0.6562737822532654\n",
      "160 0.6548956036567688\n",
      "165 0.6535223126411438\n",
      "170 0.6521536707878113\n",
      "175 0.6507898569107056\n",
      "180 0.6494308114051819\n",
      "185 0.6480764150619507\n",
      "190 0.6467268466949463\n",
      "195 0.6453818678855896\n",
      "200 0.6440415382385254\n",
      "205 0.6427059769630432\n",
      "210 0.6413750052452087\n",
      "215 0.640048623085022\n",
      "220 0.6387269496917725\n",
      "225 0.6374097466468811\n",
      "230 0.6360973119735718\n",
      "235 0.6347892880439758\n",
      "240 0.6334858536720276\n",
      "245 0.632187008857727\n",
      "250 0.6308926939964294\n",
      "255 0.6296029090881348\n",
      "260 0.6283175349235535\n",
      "265 0.6270366907119751\n",
      "270 0.6257602572441101\n",
      "275 0.624488353729248\n",
      "280 0.6232208013534546\n",
      "285 0.6219577789306641\n",
      "290 0.6206990480422974\n",
      "295 0.6194448471069336\n",
      "300 0.6181949377059937\n",
      "305 0.6169493198394775\n",
      "310 0.6157082319259644\n",
      "315 0.6144713163375854\n",
      "320 0.6132388710975647\n",
      "325 0.6120105981826782\n",
      "330 0.6107866764068604\n",
      "335 0.6095670461654663\n",
      "340 0.6083516478538513\n",
      "345 0.6071404814720154\n",
      "350 0.6059335470199585\n",
      "355 0.6047308444976807\n",
      "360 0.6035323739051819\n",
      "365 0.6023380756378174\n",
      "370 0.6011479496955872\n",
      "375 0.5999619960784912\n",
      "380 0.5987802147865295\n",
      "385 0.5976024866104126\n",
      "390 0.5964289307594299\n",
      "395 0.595259428024292\n",
      "400 0.5940940380096436\n",
      "405 0.5929327607154846\n",
      "410 0.5917755365371704\n",
      "415 0.5906223058700562\n",
      "420 0.5894731879234314\n",
      "425 0.588327944278717\n",
      "430 0.5871868133544922\n",
      "435 0.5860497355461121\n",
      "440 0.5849164724349976\n",
      "445 0.583787202835083\n",
      "450 0.5826619863510132\n",
      "455 0.581540584564209\n",
      "460 0.5804231762886047\n",
      "465 0.5793096423149109\n",
      "470 0.5781999826431274\n",
      "475 0.5770941972732544\n",
      "480 0.575992226600647\n",
      "485 0.5748941898345947\n",
      "490 0.5737999081611633\n",
      "495 0.5727095007896423\n",
      "500 0.571622908115387\n",
      "505 0.5705400705337524\n",
      "510 0.5694609880447388\n",
      "515 0.5683857202529907\n",
      "520 0.5673141479492188\n",
      "525 0.5662463903427124\n",
      "530 0.5651822686195374\n",
      "535 0.5641218423843384\n",
      "540 0.5630651712417603\n",
      "545 0.5620121359825134\n",
      "550 0.5609628558158875\n",
      "555 0.5599170923233032\n",
      "560 0.5588750839233398\n",
      "565 0.557836651802063\n",
      "570 0.5568017959594727\n",
      "575 0.5557705163955688\n",
      "580 0.5547429323196411\n",
      "585 0.5537188053131104\n",
      "590 0.5526983141899109\n",
      "595 0.5516813397407532\n",
      "600 0.5506678819656372\n",
      "605 0.549657940864563\n",
      "610 0.5486514568328857\n",
      "615 0.5476486086845398\n",
      "620 0.5466490983963013\n",
      "625 0.5456531047821045\n",
      "630 0.5446605086326599\n",
      "635 0.5436714291572571\n",
      "640 0.5426856875419617\n",
      "645 0.541703462600708\n",
      "650 0.540724515914917\n",
      "655 0.539749026298523\n",
      "660 0.5387768745422363\n",
      "665 0.5378081202507019\n",
      "670 0.5368426442146301\n",
      "675 0.5358805060386658\n",
      "680 0.5349217057228088\n",
      "685 0.5339663028717041\n",
      "690 0.5330140590667725\n",
      "695 0.5320651531219482\n",
      "700 0.5311194658279419\n",
      "705 0.530177116394043\n",
      "710 0.5292379856109619\n",
      "715 0.5283020734786987\n",
      "720 0.5273693203926086\n",
      "725 0.5264398455619812\n",
      "730 0.5255135297775269\n",
      "735 0.5245903730392456\n",
      "740 0.5236703753471375\n",
      "745 0.5227535963058472\n",
      "750 0.52183997631073\n",
      "755 0.5209293961524963\n",
      "760 0.5200219750404358\n",
      "765 0.5191176533699036\n",
      "770 0.5182164907455444\n",
      "775 0.5173181891441345\n",
      "780 0.5164231657981873\n",
      "785 0.5155311822891235\n",
      "790 0.5146421790122986\n",
      "795 0.5137561559677124\n",
      "800 0.5128731727600098\n",
      "805 0.5119932889938354\n",
      "810 0.5111163258552551\n",
      "815 0.5102424025535583\n",
      "820 0.5093714594841003\n",
      "825 0.5085033774375916\n",
      "830 0.5076382756233215\n",
      "835 0.5067761540412903\n",
      "840 0.505916953086853\n",
      "845 0.5050606727600098\n",
      "850 0.504207193851471\n",
      "855 0.5033567547798157\n",
      "860 0.5025090575218201\n",
      "865 0.5016643404960632\n",
      "870 0.5008223652839661\n",
      "875 0.4999832510948181\n",
      "880 0.49914705753326416\n",
      "885 0.4983135759830475\n",
      "890 0.49748295545578003\n",
      "895 0.49665510654449463\n",
      "900 0.49583005905151367\n",
      "905 0.49500784277915955\n",
      "910 0.4941883683204651\n",
      "915 0.4933716058731079\n",
      "920 0.4925575852394104\n",
      "925 0.49174627661705017\n",
      "930 0.4909377694129944\n",
      "935 0.4901319146156311\n",
      "940 0.48932868242263794\n",
      "945 0.4885282516479492\n",
      "950 0.487730473279953\n",
      "955 0.4869353473186493\n",
      "960 0.4861428737640381\n",
      "965 0.4853530824184418\n",
      "970 0.4845658242702484\n",
      "975 0.4837813079357147\n",
      "980 0.4829992651939392\n",
      "985 0.48221996426582336\n",
      "990 0.4814431965351105\n",
      "995 0.48066893219947815\n",
      "predicted 1 hour  1.0 False\n",
      "predicted 7 hour  7.0 True\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(1000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(epoch, loss.item())\n",
    "        \n",
    "    # Zero gradients, perform a backward pass, and update the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "# After training\n",
    "hour = torch.Tensor([[1.0]], device = device)\n",
    "print(\"predicted 1 hour \", 1.0, model(hour).item() > 0.5)\n",
    "hour = torch.Tensor([[7.0]], device = device)\n",
    "print(\"predicted 7 hour \", 7.0, model(hour).item() > 0.5)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
